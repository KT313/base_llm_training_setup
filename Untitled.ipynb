{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b0373747-2092-4645-a722-5c7dffab5077",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1d87598b-5556-44dc-980e-de75b0c85267",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = transformers.AutoModelForCausalLM.from_pretrained(\"workspace/FoPE-context512-mini-test/latest-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f1c8b50-6bc7-480e-9a7c-0e5760f4e088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OlmoForCausalLM(\n",
       "  (model): OlmoModel(\n",
       "    (embed_tokens): Embedding(50304, 384, padding_idx=1)\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x OlmoDecoderLayer(\n",
       "        (self_attn): OlmoSdpaAttention(\n",
       "          (q_proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (k_proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (v_proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (o_proj): Linear(in_features=384, out_features=384, bias=False)\n",
       "          (rotary_emb): OlmoRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): OlmoMLP(\n",
       "          (gate_proj): Linear(in_features=384, out_features=1536, bias=False)\n",
       "          (up_proj): Linear(in_features=384, out_features=1536, bias=False)\n",
       "          (down_proj): Linear(in_features=1536, out_features=384, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): OlmoLayerNorm()\n",
       "        (post_attention_layernorm): OlmoLayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): OlmoLayerNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=384, out_features=50304, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2aaca36b-5d55-4c7d-b424-f9f31e27c514",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"workspace/FoPE-context512-mini-test/latest-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e104122b-5da8-4fca-9c21-f9a973abe1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_to_generate = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f84f59bc-1c26-460a-813c-4226ab727318",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"owo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "609230a5-2ea7-4eb4-b314-d357f06e1430",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 32/32 [00:00<00:00, 49.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "owo, and the other two-thirds of the new, and “the most important” of the new new and more.\n",
      "The new new, more efficient and\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "running_text = text\n",
    "for i in tqdm(range(tokens_to_generate)):\n",
    "    tokens = tokenizer(running_text, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        out = model(tokens['input_ids'])\n",
    "    pred = torch.argmax(out['logits'][:, -1], dim=-1)\n",
    "    output_token = tokenizer.decode(pred.tolist())\n",
    "    running_text += output_token\n",
    "\n",
    "print(running_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2f2c85d6-1791-4cae-be33-ae526bdb321e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e27ab448-510a-4d09-8126-9b702fd9eff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[43954,    13,   359,   476,  1333,   326,   253]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bdfbcb1f-20c9-47f3-8171-79959517c824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1b23c4b6-8ec8-443e-8d44-75c3af346b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 50304])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['logits'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4e770d8c-af01-45b7-a98e-91fe8253040f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 50304])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['logits'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "23238034-eeff-41fa-bb12-9bcbfc6ca82a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "496ccf16-d046-4642-b473-43a78e9d8b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1682])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "404caa29-85ee-4ee6-9f3e-6bc17a276e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6e2a2aaa-ad41-45e5-b441-05c5acf97d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "16581069-8dbb-4472-b0b9-c0d10507b9f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Certainly, we can say that the best'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
